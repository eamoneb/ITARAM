TODO

1. After talking to Zee, file ticket with DRE team to get extract from production postgres data warehouse

2. get postgres data dump loaded into our own postgres db. We'll each keep copies locally for now.

3. use various org.apache.spark.ml functions to do initial statistical analysis of the incident data - frequency, deviation, binning, median, mean, etc.

4. advanced SQL queries to provide some of the analytics

5. use org.apache.spark.ml.clustering.KMeans function to do clustering. first Cory and Eamon need to decide which response features to use

6. lower priority - also get an extract from the production (or dev or qa) mongo system, and load into our own mongo we can both access


* remove hard-coding - create a config or properties object for urls, usernames, passwords, etc.
create a script to load data into mongodb, similar to the sql scripts for postgresql

* work with Michael to figure out to display our results on a new scratch ITA dashboard tab

* advanced sql queries (existing ITA dashboard is simplistic - only has # open, and recent trend
      incidents with or without open conference bridge - how it affects response
      incidents with or without escalation - how it affects response
      incidents with lowest skilled assignees, or with highest skilled assignees - how it affects response
      compare rate-of-efficientcy-of-response with same week / month / quarter last year. Show rate of change. Bonus: account for seasonality
      show rate of change in efficiency-of-response
      define efficiency-of-response. Some function of time-taken, number of escalations, number of people?

* statistics: frequency, mean, binning, deviation, median, correlation, covariance, etc.

machine learning
----------------
clustering:
-----------
* use kmeans function - following features are likely - time to respond, time to resolve, # of assignees, # of escalations
* use clusters to work on situations not on individual events

classification:
---------------
* can we get configuration-change data from a partnering CMDB? If so, we could predict future critical events based on current or recent configuration changes
* establish root-cause. So long as we can record the root cause from known events in history
* detect service-impact issues before users even call to report
* otherwise do multi class classification based on how much an incident affects users - de-prioritize the ones that don't affect much
* probably use random forest for classification with least noise
* use naiive bayes to prioritize incidents to work on, based on their value to the business and probability of affecting users - noise reduction

regression:
-----------
* predict the rate of change in efficiency-of-response based on dependent vcariable ???
* maybe also predict the amount of $ an incident will cost

data preparation:
-----------------
we might have to use Principal Component Analysis to reduce number of features

other:
------
* pattern mining?
add comments
add tags for scaladoc (similar to javadoc)
add unit tests with scalatest
invite one of the other teams to review our code. chris cebelenski (ipaas team) seems to know a lot about scala

